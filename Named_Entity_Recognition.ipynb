{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyODesS3xz8ckDxU6ZvCgS6/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ec900529ba104d6f96fca0486acd32f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ec86801ca91c4c5781fc843586179c21",
              "IPY_MODEL_6491f36f27444c22bd388d41de1a678e",
              "IPY_MODEL_1d3dc6951dd744aeb413e4231d9a315a"
            ],
            "layout": "IPY_MODEL_24bf1c52831f45a1a52605126ef43315"
          }
        },
        "ec86801ca91c4c5781fc843586179c21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_83a0a54d88374c779548c6efd9167370",
            "placeholder": "​",
            "style": "IPY_MODEL_c4798f9420b54ad5bb22e02e2ff95dc5",
            "value": "Map: 100%"
          }
        },
        "6491f36f27444c22bd388d41de1a678e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7b51229a67d743adb9b6ccc19ecea431",
            "max": 3250,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c3759a6291164f7d973e52fb091187b4",
            "value": 3250
          }
        },
        "1d3dc6951dd744aeb413e4231d9a315a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_56a26f9e95e84a3fa800ddaba7d81ac6",
            "placeholder": "​",
            "style": "IPY_MODEL_dfd8fd410c4b444cbc0d48d25c91d1ff",
            "value": " 3250/3250 [00:01&lt;00:00, 2087.58 examples/s]"
          }
        },
        "24bf1c52831f45a1a52605126ef43315": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "83a0a54d88374c779548c6efd9167370": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c4798f9420b54ad5bb22e02e2ff95dc5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7b51229a67d743adb9b6ccc19ecea431": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c3759a6291164f7d973e52fb091187b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "56a26f9e95e84a3fa800ddaba7d81ac6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dfd8fd410c4b444cbc0d48d25c91d1ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Daryldactyl/Training_Transformers/blob/main/Named_Entity_Recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# NER (Named Entity Recognition)\n",
        "### Import the Dataset"
      ],
      "metadata": {
        "id": "cnXlap9QMyki"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "zIuo-zgRtRvf"
      },
      "outputs": [],
      "source": [
        "!pip install transformers datasets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "data = load_dataset('conll2003')\n",
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K95VTve3KreY",
        "outputId": "926e42e3-ec45-4958-8a5a-a5d734f6b646"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
              "        num_rows: 14041\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
              "        num_rows: 3250\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
              "        num_rows: 3453\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualize the Dataset"
      ],
      "metadata": {
        "id": "l8TSATV7NACB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data['train'][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LweX1-_2K7O0",
        "outputId": "ffcd568d-f1f7-4391-9e73-edc2ebed99cb"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'id': '0',\n",
              " 'tokens': ['EU',\n",
              "  'rejects',\n",
              "  'German',\n",
              "  'call',\n",
              "  'to',\n",
              "  'boycott',\n",
              "  'British',\n",
              "  'lamb',\n",
              "  '.'],\n",
              " 'pos_tags': [22, 42, 16, 21, 35, 37, 16, 21, 7],\n",
              " 'chunk_tags': [11, 21, 11, 12, 21, 22, 11, 12, 0],\n",
              " 'ner_tags': [3, 0, 7, 0, 0, 0, 7, 0, 0]}"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label_names = data['train'].features['ner_tags'].feature.names\n",
        "label_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yUFWXoWYLZtu",
        "outputId": "703fea65-a90e-431b-8ecc-991100c0dbe0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Build the Tokenizer"
      ],
      "metadata": {
        "id": "e-QrzxwRNDYI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "checkpoint = 'distilbert-base-cased'\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
      ],
      "metadata": {
        "id": "4FnHE5yVLlEn"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "idx = 0\n",
        "t = tokenizer(data['train'][idx]['tokens'], is_split_into_words=True)\n",
        "t"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "__JQWwFfMGF7",
        "outputId": "c40ef601-6b94-4d33-e50a-a02255957507"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': [101, 7270, 22961, 1528, 1840, 1106, 21423, 1418, 2495, 12913, 119, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t.tokens()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N9MGLeuNMN95",
        "outputId": "02c0c50e-5875-4c26-9faf-fecbd97824e9"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['[CLS]',\n",
              " 'EU',\n",
              " 'rejects',\n",
              " 'German',\n",
              " 'call',\n",
              " 'to',\n",
              " 'boycott',\n",
              " 'British',\n",
              " 'la',\n",
              " '##mb',\n",
              " '.',\n",
              " '[SEP]']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Target alignment\n",
        "- As we can see the word lamb is split into 2 tokens and the CLS and SEP tokens have been added. In order to match our ner_tags we will need to make sure that the tag for lamb is duplicated to accompany both parts of the token\n",
        "- We will also need to create tags for the CLS and SEP tokens\n",
        "- We will need to make sure if the token is split that the tag goes from B-PER to I-PER for example as B is for beginning and I is for Inner"
      ],
      "metadata": {
        "id": "rWT2qvTpMZPh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Example of Word IDs for first sentence\n",
        "t.word_ids()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mdi9pzcUeijD",
        "outputId": "33a0fbee-c774-45e5-939e-c9b718ffd62d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[None, 0, 1, 2, 3, 4, 5, 6, 7, 7, 8, None]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC']\n",
        "# Map Begin IDs to Inner IDs\n",
        "begin2inside = {\n",
        "    1:2,\n",
        "    3:4,\n",
        "    5:6,\n",
        "    7:8,\n",
        "}"
      ],
      "metadata": {
        "id": "fqOatCqDhpnQ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def align_targets(labels, word_ids):\n",
        "  aligned_labels = []\n",
        "  last_word = None\n",
        "  for word in word_ids:\n",
        "    if word is None:\n",
        "      label = -100 #for CLS and SEP tokens\n",
        "    elif word != last_word:\n",
        "      #new word\n",
        "      label = labels[word]\n",
        "    else:\n",
        "      #same as previous word (got split)\n",
        "      label = labels[word]\n",
        "\n",
        "      #change the B to an I for the tag\n",
        "      if label in begin2inside:\n",
        "        label = begin2inside[label]\n",
        "\n",
        "    aligned_labels.append(label)\n",
        "\n",
        "    last_word = word\n",
        "\n",
        "  return aligned_labels"
      ],
      "metadata": {
        "id": "WZv2HFZOiI5-"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#test function on first sentence\n",
        "labels = data['train'][idx]['ner_tags']\n",
        "word_ids = t.word_ids()\n",
        "print(f'Labels: {labels} Total: {len(labels)}\\nWord IDs: {word_ids} Total: {len(word_ids)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZV8uZ7y5jzB_",
        "outputId": "6ae8c9d3-12fd-44c1-d4eb-980844522106"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Labels: [3, 0, 7, 0, 0, 0, 7, 0, 0] Total: 9\n",
            "Word IDs: [None, 0, 1, 2, 3, 4, 5, 6, 7, 7, 8, None] Total: 12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "aligned_targets = align_targets(labels, word_ids)\n",
        "aligned_targets\n",
        "\n",
        "#Looking at the loop, none becomes -100 then last word is equal to none, 0 becomes 3 and last word becomes 0, 1 becomes 0 then last word becomes 1 all the way up to word 7\n",
        "#Last word = 7 so second 7 becomes 0, since its not in begin2inside it stays as 0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "22e2YFeMkBRn",
        "outputId": "4a33a637-6059-4ba6-c90f-eb1442b7080c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[-100, 3, 0, 7, 0, 0, 0, 7, 0, 0, 0, -100]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "align_labels = [label_names[t] if t >= 0 else None for t in aligned_targets]\n",
        "for x, y in zip(t.tokens(), align_labels):\n",
        "  print(f'{x}\\t{y}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t_D6mgmkkb1q",
        "outputId": "277680ab-9980-48b0-e272-c7df1b544e6f"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CLS]\tNone\n",
            "EU\tB-ORG\n",
            "rejects\tO\n",
            "German\tB-MISC\n",
            "call\tO\n",
            "to\tO\n",
            "boycott\tO\n",
            "British\tB-MISC\n",
            "la\tO\n",
            "##mb\tO\n",
            ".\tO\n",
            "[SEP]\tNone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Now that Target Alignment is confirmed to be working, lets build the tokenize function"
      ],
      "metadata": {
        "id": "wJZYENZhlein"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_fn(batch):\n",
        "  #Tokenize the inputs (the tokenized version of each word ex: '[CLS]','EU','rejects','German','call','to','boycott','British','la','##mb','.','[SEP]')\n",
        "  tokenized_inputs = tokenizer(batch['tokens'], truncation=True, is_split_into_words=True)\n",
        "\n",
        "  #Get the original ner tags (ex: ['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC'])\n",
        "  labels_batch = batch['ner_tags']\n",
        "  aligned_labels_batch = []\n",
        "  for i, labels in enumerate(labels_batch):\n",
        "\n",
        "    #Iterate over each sentence in tokenized inputs and get the list of word ids\n",
        "    word_ids = tokenized_inputs.word_ids(i)\n",
        "\n",
        "    #Use the label per label in labels batch and now your iterated sentence from the tokenized inputs into our align function. This will iteratively align every sentence to its labels in the dataset\n",
        "    aligned_labels_batch.append(align_targets(labels, word_ids))\n",
        "\n",
        "  tokenized_inputs['labels'] = aligned_labels_batch\n",
        "\n",
        "  return tokenized_inputs"
      ],
      "metadata": {
        "id": "oxF3vY5qmKBm"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Remember for our model we will need a column named inputs_ids and another named labels\n",
        "data['train'].column_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lePLfmZtoAAF",
        "outputId": "7d522971-6232-4b81-e9e8-a1b75cae8cdf"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags']"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_datasets = data.map(\n",
        "    tokenize_fn,\n",
        "    batched=True,\n",
        "    remove_columns = data['train'].column_names\n",
        ")\n",
        "\n",
        "tokenized_datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292,
          "referenced_widgets": [
            "ec900529ba104d6f96fca0486acd32f3",
            "ec86801ca91c4c5781fc843586179c21",
            "6491f36f27444c22bd388d41de1a678e",
            "1d3dc6951dd744aeb413e4231d9a315a",
            "24bf1c52831f45a1a52605126ef43315",
            "83a0a54d88374c779548c6efd9167370",
            "c4798f9420b54ad5bb22e02e2ff95dc5",
            "7b51229a67d743adb9b6ccc19ecea431",
            "c3759a6291164f7d973e52fb091187b4",
            "56a26f9e95e84a3fa800ddaba7d81ac6",
            "dfd8fd410c4b444cbc0d48d25c91d1ff"
          ]
        },
        "id": "AYaSgfy7oCOw",
        "outputId": "cac0cef8-25eb-4db4-960c-6e2d7b03b529"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/3250 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ec900529ba104d6f96fca0486acd32f3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['input_ids', 'attention_mask', 'labels'],\n",
              "        num_rows: 14041\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['input_ids', 'attention_mask', 'labels'],\n",
              "        num_rows: 3250\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['input_ids', 'attention_mask', 'labels'],\n",
              "        num_rows: 3453\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The tokenizer creates the input_ids and attention mask column and our tokenize function creates the labels column"
      ],
      "metadata": {
        "id": "m6YjN3sjog47"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Instantiate the Data Collator\n",
        "The Data Collator pads all the columns in the dataset to be the same length but also pads the attention mask so the model knows to ignore the padding during training"
      ],
      "metadata": {
        "id": "WJXoASgGp2-L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import DataCollatorForTokenClassification\n",
        "\n",
        "data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)"
      ],
      "metadata": {
        "id": "W_0OWkrMxguu"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "[tokenized_datasets['train'][i] for i in range(2)]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u0lisWKXxsvj",
        "outputId": "8f9e02e8-72a9-448b-d083-3f67ba7c1420"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'input_ids': [101,\n",
              "   7270,\n",
              "   22961,\n",
              "   1528,\n",
              "   1840,\n",
              "   1106,\n",
              "   21423,\n",
              "   1418,\n",
              "   2495,\n",
              "   12913,\n",
              "   119,\n",
              "   102],\n",
              "  'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
              "  'labels': [-100, 3, 0, 7, 0, 0, 0, 7, 0, 0, 0, -100]},\n",
              " {'input_ids': [101, 1943, 14428, 102],\n",
              "  'attention_mask': [1, 1, 1, 1],\n",
              "  'labels': [-100, 1, 2, -100]}]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch = data_collator([tokenized_datasets['train'][i] for i in range(2)])\n",
        "batch['labels']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mCE5lD55xzIg",
        "outputId": "7da67bf4-cb42-4d70-9918-ca78fecdcf02"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-100,    3,    0,    7,    0,    0,    0,    7,    0,    0,    0, -100],\n",
              "        [-100,    1,    2, -100, -100, -100, -100, -100, -100, -100, -100, -100]])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notice the padding for the labels are marked as -100 to be ignored by the model"
      ],
      "metadata": {
        "id": "3klMpl9pyZHr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Metrics\n",
        "Considering we are classifying tokens accuracy won't be a good measurement because we have multiple outputs for varying inputs\n",
        "\n",
        "We will use seqeval which has the sole purpose of computing metrics for NLP Tasks with sequence targets\n",
        "\n",
        "Keep in mind we will need to remove the pad tokens when computing the loss function as to not scew our accuracy in order to bias the model to predict all pad tokens to boost accuracy metric"
      ],
      "metadata": {
        "id": "lo_7wZQpypC1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install seqeval"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FuhiKdjlzJqF",
        "outputId": "58f0f35c-db9d-4eac-fab6-1a92e06f81b9"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: seqeval in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from seqeval) (1.25.2)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.10/dist-packages (from seqeval) (1.2.2)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval) (3.5.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_metric\n",
        "\n",
        "metric = load_metric('seqeval')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WX8JLJrszLSy",
        "outputId": "b36ca045-5362-407f-d806-5a23681c1565"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-21-c876b65aca5e>:3: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n",
            "  metric = load_metric('seqeval')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Test it out with the proper labels (since seqeval is expecting true labels)\n",
        "metric.compute(\n",
        "    predictions = [['O', 'O', 'I-ORG', 'B-MISC']],\n",
        "    references = [['O', 'B-ORG', 'I-ORG', 'B-MISC']]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9sRo5R7u2zJX",
        "outputId": "cdc01322-7a12-4cf5-ab0c-ca3065064253"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'MISC': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'number': 1},\n",
              " 'ORG': {'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 1},\n",
              " 'overall_precision': 0.5,\n",
              " 'overall_recall': 0.5,\n",
              " 'overall_f1': 0.5,\n",
              " 'overall_accuracy': 0.75}"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Setup our compute metrics function"
      ],
      "metadata": {
        "id": "1sj-U-jg3SSc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def compute_metrics(logits_and_labels):\n",
        "  logits, labels = logits_and_labels\n",
        "  preds = np.argmax(logits, axis=-1)\n",
        "\n",
        "  #remove the -100 from labels and predictions\n",
        "  str_labels = [\n",
        "      [label_names[t] for t in label if t != -100] for label in labels #For each label in the list of labels we will go through and remove the -100 tag and converting each tag to its str name\n",
        "  ]\n",
        "\n",
        "  #We will still get loss if the model predicts a -100 for the actual label so we know the model got it wrong and the prediction sequence will be the same length as the target sequence\n",
        "  str_preds = [\n",
        "      [label_names[p] for p, t in zip(pred, targ) if t != -100] for pred, targ in zip(preds, labels)\n",
        "  ]\n",
        "\n",
        "  the_metrics = metric.compute(predictions=str_preds, references=str_labels)\n",
        "\n",
        "  return {\n",
        "      'precision': the_metrics['overall_precision'],\n",
        "      'recall': the_metrics['overall_recall'],\n",
        "      'f1': the_metrics['overall_f1'],\n",
        "      'accuracy': the_metrics['overall_accuracy']\n",
        "  }"
      ],
      "metadata": {
        "id": "_rENnwE23b2d"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load in a Model and Fine-Tune with our Dataset"
      ],
      "metadata": {
        "id": "8UbkTGYe5wt-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create Labels to specify to model so the labels will come out correctly instead of as LABEL_0, LABEL_1, etc.\n",
        "id2label = {k: v for k, v in enumerate(label_names)}\n",
        "label2id = {v:k for k, v in id2label.items()}"
      ],
      "metadata": {
        "id": "SJM3TFQX5c5I"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForTokenClassification\n",
        "\n",
        "model = AutoModelForTokenClassification.from_pretrained(checkpoint, id2label=id2label, label2id=label2id)\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EeTZwkw06AYR",
        "outputId": "19b67ad1-421e-4f38-81c3-e17409c71c65"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DistilBertForTokenClassification were not initialized from the model checkpoint at distilbert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DistilBertForTokenClassification(\n",
              "  (distilbert): DistilBertModel(\n",
              "    (embeddings): Embeddings(\n",
              "      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (transformer): Transformer(\n",
              "      (layer): ModuleList(\n",
              "        (0-5): 6 x TransformerBlock(\n",
              "          (attention): MultiHeadSelfAttention(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (ffn): FFN(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (activation): GELUActivation()\n",
              "          )\n",
              "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=9, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Set up Training Arguments and Trainer"
      ],
      "metadata": {
        "id": "vIQTnENI6Pbp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments, Trainer"
      ],
      "metadata": {
        "id": "T_AneSQa6fQx"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers[torch]"
      ],
      "metadata": {
        "id": "oMxPerBY7OSu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install accelerate -U"
      ],
      "metadata": {
        "id": "8o53JWwI7uHa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir='distilbert-finetuned-ner',\n",
        "    eval_strategy='epoch',\n",
        "    save_strategy='epoch',\n",
        "    learning_rate=2e-5,\n",
        "    num_train_epochs=1,\n",
        "    weight_decay=0.01\n",
        ")"
      ],
      "metadata": {
        "id": "eCDl7YvU6nit"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_datasets['train'],\n",
        "    eval_dataset=tokenized_datasets['validation'],\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics,\n",
        "    tokenizer=tokenizer\n",
        ")"
      ],
      "metadata": {
        "id": "ghCsE77b8i3-"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "pYJK09Z77JHQ",
        "outputId": "279d00dc-5b77-49f3-e4b9-361b06b17dfa"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1756' max='1756' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1756/1756 1:07:21, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.092500</td>\n",
              "      <td>0.084470</td>\n",
              "      <td>0.880241</td>\n",
              "      <td>0.907943</td>\n",
              "      <td>0.893878</td>\n",
              "      <td>0.975776</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=1756, training_loss=0.1487948910793574, metrics={'train_runtime': 4047.3827, 'train_samples_per_second': 3.469, 'train_steps_per_second': 0.434, 'total_flos': 153520489309824.0, 'train_loss': 0.1487948910793574, 'epoch': 1.0})"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.save_model('Sentence_NER_Model')"
      ],
      "metadata": {
        "id": "l09Itl6Z-CSS"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load Saved Model to test on Token classification"
      ],
      "metadata": {
        "id": "E4Y3c9SN85IM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "ner = pipeline(\n",
        "    'token-classification',\n",
        "    model = 'Sentence_NER_Model',\n",
        "    aggregation_strategy='simple',\n",
        ")"
      ],
      "metadata": {
        "id": "7G0LSCrw-AZW"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = 'Bill Gates was the CEO of Microsoft in Seattle, Washington.'\n",
        "\n",
        "ner(sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sW5FpbaA-jVl",
        "outputId": "dff5600d-2b4a-46f6-9412-fb8aa616afaf"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'entity_group': 'PER',\n",
              "  'score': 0.9970716,\n",
              "  'word': 'Bill Gates',\n",
              "  'start': 0,\n",
              "  'end': 10},\n",
              " {'entity_group': 'ORG',\n",
              "  'score': 0.9879116,\n",
              "  'word': 'Microsoft',\n",
              "  'start': 26,\n",
              "  'end': 35},\n",
              " {'entity_group': 'LOC',\n",
              "  'score': 0.9949267,\n",
              "  'word': 'Seattle',\n",
              "  'start': 39,\n",
              "  'end': 46},\n",
              " {'entity_group': 'LOC',\n",
              "  'score': 0.9943825,\n",
              "  'word': 'Washington',\n",
              "  'start': 48,\n",
              "  'end': 58}]"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mapping = {'PER': 'Person', 'ORG': 'Organization', 'LOC': 'Location'}\n",
        "for entity in ner(sentence):\n",
        "  type_of_entity = entity['entity_group']\n",
        "  a_or_an = ('an' if entity['entity_group'] == 'ORG' else 'a')\n",
        "  print(f\"I am {round(entity['score'] * 100, 2)}% sure that {entity['word']} is {a_or_an} {mapping[type_of_entity]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LOF4czg59xqv",
        "outputId": "7c18136c-91f2-4a95-b537-3182d34910d8"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I am 99.71% sure that Bill Gates is a Person\n",
            "I am 98.79% sure that Microsoft is an Organization\n",
            "I am 99.49% sure that Seattle is a Location\n",
            "I am 99.44% sure that Washington is a Location\n"
          ]
        }
      ]
    }
  ]
}